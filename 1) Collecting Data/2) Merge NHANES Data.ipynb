{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lO7CbIiKNuQl"
   },
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3mguPCLeNgMc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17719,
     "status": "ok",
     "timestamp": 1747384755928,
     "user": {
      "displayName": "Aldy Revi",
      "userId": "00612481979328314286"
     },
     "user_tz": -420
    },
    "id": "sT_VxO8SNp8Y",
    "outputId": "5528145f-4f65-49c0-e941-6b8debe15822"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive')\n",
    "project_path = \"/content/drive/MyDrive/ComBio\"\n",
    "root_folder = f\"{project_path}/Dataset\"\n",
    "output_folder = f\"{project_path}/Dataset/Processed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GHRTZzpNxeX"
   },
   "source": [
    "## Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lNP0c5zPNexZ"
   },
   "outputs": [],
   "source": [
    "def clean_nhanes_codes(df):\n",
    "    df_cleaned = df.copy()\n",
    "    for col in df_cleaned.columns:\n",
    "        col_data = df_cleaned[col]\n",
    "        is_categorical = False\n",
    "        if col.endswith(('LC', 'FC', 'SI', 'IND', 'CODE')):\n",
    "            is_categorical = True\n",
    "\n",
    "        elif col_data.nunique() < 10 and pd.api.types.is_numeric_dtype(col_data):\n",
    "            is_categorical = True\n",
    "\n",
    "        if pd.api.types.is_numeric_dtype(col_data) and not is_categorical:\n",
    "            extreme_mask = (col_data.abs() < 1e-10) & (col_data != 0)\n",
    "            if extreme_mask.any():\n",
    "                print(f\"Kolom {col}: mengganti {extreme_mask.sum()} nilai ekstrim dengan NaN\")\n",
    "                df_cleaned.loc[extreme_mask, col] = np.nan\n",
    "\n",
    "        if pd.api.types.is_numeric_dtype(col_data):\n",
    "            # Nilai negatif dalam NHANES:\n",
    "            # -1: Refused\n",
    "            # -2: Don't know\n",
    "            # -7: Refused to answer\n",
    "            # -9: Don't know/missing\n",
    "            nhanes_codes = [-1, -2, -7, -9]\n",
    "            for code in nhanes_codes:\n",
    "                code_mask = col_data == code\n",
    "                if code_mask.any():\n",
    "                    print(f\"Kolom {col}: mengganti {code_mask.sum()} nilai kode {code} dengan NaN\")\n",
    "                    df_cleaned.loc[code_mask, col] = np.nan\n",
    "\n",
    "    return df_cleaned\n",
    "\n",
    "def process_nhanes_period(folder, suffix, filename_csv):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"MEMPROSES DATA NHANES DI FOLDER: {folder}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    try:\n",
    "        if not os.path.exists(folder):\n",
    "            print(f\"Error: Folder {folder} tidak ditemukan!\")\n",
    "            return False\n",
    "\n",
    "        datasets = {}\n",
    "        files_to_read = {\n",
    "            \"demo\": f\"DEMO{suffix}.XPT\",\n",
    "            \"biopro\": f\"BIOPRO{suffix}.XPT\",\n",
    "            \"hepc\": f\"HEPC{suffix}.XPT\",\n",
    "            \"mcq\": f\"MCQ{suffix}.XPT\",\n",
    "            \"alq\": f\"ALQ{suffix}.XPT\",\n",
    "            \"duq\": f\"DUQ{suffix}.XPT\",\n",
    "        }\n",
    "\n",
    "        for name, filename in files_to_read.items():\n",
    "            file_path = os.path.join(folder, filename)\n",
    "            if not os.path.exists(file_path):\n",
    "                print(f\"Warning: File {filename} tidak ditemukan di {folder}\")\n",
    "                print(f\"Coba mencari file alternatif...\")\n",
    "\n",
    "                possible_files = [f for f in os.listdir(folder) if f.lower().startswith(name.lower())]\n",
    "                if possible_files:\n",
    "                    alt_file = possible_files[0]\n",
    "                    print(f\"Menggunakan file alternatif: {alt_file}\")\n",
    "                    file_path = os.path.join(folder, alt_file)\n",
    "                else:\n",
    "                    print(f\"Tidak ditemukan file alternatif untuk {name}. Melewati dataset ini.\")\n",
    "                    continue\n",
    "\n",
    "            try:\n",
    "                print(f\"Membaca file {file_path}...\")\n",
    "                datasets[name] = pd.read_sas(file_path)\n",
    "                print(f\"Berhasil membaca {filename} dengan {len(datasets[name])} baris dan {len(datasets[name].columns)} kolom\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error saat membaca {filename}: {str(e)}\")\n",
    "                print(\"Melewati dataset ini.\")\n",
    "                continue\n",
    "\n",
    "        if len(datasets) < 2:\n",
    "            print(\"Terlalu sedikit dataset yang berhasil dibaca untuk melakukan merge.\")\n",
    "            print(\"Minimal diperlukan 2 dataset untuk melanjutkan.\")\n",
    "            return False\n",
    "\n",
    "        print(\"\\nMembersihkan nilai kode khusus di setiap dataset...\")\n",
    "        cleaned_datasets = {}\n",
    "        for name, data in datasets.items():\n",
    "            cleaned_datasets[name] = clean_nhanes_codes(data)\n",
    "\n",
    "        print(\"\\nMelakukan merge dataset...\")\n",
    "        base_dataset_name = \"demo\" if \"demo\" in cleaned_datasets else list(cleaned_datasets.keys())[0]\n",
    "        merged_df = cleaned_datasets[base_dataset_name]\n",
    "        print(f\"Dataset awal ({base_dataset_name}): {merged_df.shape}\")\n",
    "\n",
    "        for name, data in cleaned_datasets.items():\n",
    "            if name == base_dataset_name:\n",
    "                continue\n",
    "\n",
    "            prev_shape = merged_df.shape\n",
    "            how_join = \"inner\" if name in [\"biopro\", \"hepc\"] else \"left\"\n",
    "            merged_df = merged_df.merge(data, on=\"SEQN\", how=how_join)\n",
    "            print(f\"Setelah merge dengan {name}: {merged_df.shape} (kehilangan {prev_shape[0] - merged_df.shape[0]} baris)\")\n",
    "\n",
    "        print(f\"\\nDataset gabungan final shape: {merged_df.shape}\")\n",
    "\n",
    "        print(\"Memeriksa nilai khusus setelah merge...\")\n",
    "        df_final = clean_nhanes_codes(merged_df)\n",
    "\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        output_filename = f\"{filename_csv}.csv\"\n",
    "        output_path = os.path.join(output_folder, output_filename)\n",
    "        print(f\"Menyimpan hasil ke {output_path}...\")\n",
    "        df_final.to_csv(output_path, index=False)\n",
    "        print(f\"Dataset berhasil disimpan!\")\n",
    "\n",
    "        print(\"\\nInformasi tentang dataset:\")\n",
    "        for dtype, count in df_final.dtypes.value_counts().items():\n",
    "            print(f\"- {count} kolom dengan tipe data {dtype}\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error saat memproses data di folder {folder}: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25034,
     "status": "ok",
     "timestamp": 1747384795536,
     "user": {
      "displayName": "Aldy Revi",
      "userId": "00612481979328314286"
     },
     "user_tz": -420
    },
    "id": "2cNuTW0wPpf1",
    "outputId": "b869ffa3-11e7-4623-97a2-428adf689288"
   },
   "outputs": [],
   "source": [
    "print(\"PEMROSESAN DATA NHANES UNTUK PERIODE 2005-2006 SAMPAI 2017-2018\")\n",
    "print(\"===============================================================\")\n",
    "\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "periods = [\n",
    "    (f\"{root_folder}/2005_2006\", \"_D\", \"2005-2006\"),  # Suffix D\n",
    "    (f\"{root_folder}/2007_2008\", \"_E\", \"2007-2008\"),  # Suffix E\n",
    "    (f\"{root_folder}/2009_2010\", \"_F\", \"2009-2010\"),  # Suffix F\n",
    "    (f\"{root_folder}/2011_2012\", \"_G\", \"2011-2012\"),  # Suffix G\n",
    "    (f\"{root_folder}/2013_2014\", \"_H\", \"2013-2014\"),  # Suffix H\n",
    "    (f\"{root_folder}/2015_2016\", \"_I\", \"2015-2016\"),  # Suffix I\n",
    "    (f\"{root_folder}/2017_2018\", \"_J\", \"2017-2018\"),  # Suffix J\n",
    "]\n",
    "\n",
    "success_count = 0\n",
    "total_periods = len(periods)\n",
    "\n",
    "for folder, suffix, filename in periods:\n",
    "    print(f\"\\nMemproses periode {filename} dengan suffix {suffix}...\")\n",
    "    if process_nhanes_period(folder, suffix, filename):\n",
    "        success_count += 1\n",
    "        print(f\"\\n✅ Data {filename} berhasil diproses\")\n",
    "    else:\n",
    "        print(f\"\\n❌ Gagal memproses data {filename}\")\n",
    "\n",
    "print(f\"\\nPROSES SELESAI. Berhasil memproses {success_count} dari {total_periods} periode.\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMwli43tVwyDRuZpYlZgCAt",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
